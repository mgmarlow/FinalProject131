}
return(count)
}
# test lump_errors function
0 == lump_error(c(1,2,2), c(2,1,1)) # true
lump_error <- function(classes, clusters) {
# inputs: arg1: vector of classes
#         arg2: vector of clusters
# outputs: number of lumping errors
#
# usage: lump_errors(c(1,2,2), c(2,1,1))
#
count <- 0
for (i in 1:(length(clusters)-1)) {
# loop through all clusters
for (y in i:(length(clusters)-1)) {
# check if in same cluster
if (clusters[i] == clusters[y]) {
# check if same class
if(classes[i] != classes[y]) {
# if same class, add lump error
count <- count + 1
}
}
}
}
return(count)
}
# test lump_errors function
0 == lump_error(c(1,2,2), c(2,1,1)) # true
2 == lump_error(c(1,2,2), c(1,1,1)) # true
0 == lump_error(c(1,2,2), c(4,5,6)) # true
lump_error(c(1,2,2), c(1,1,1)) # true
x <- [1, 2, 3, 4, 5]
x <- c(1, 2, 3, 4, 5)
x
x.length
length(x)
for (i in 1:length(x)) { i }
for (i in 1:length(x)) { (i) }
print('2')
for (i in 1:length(x)) { print(i) }
lump_error <- function(classes, clusters) {
# inputs: arg1: vector of classes
#         arg2: vector of clusters
# outputs: number of lumping errors
#
# usage: lump_errors(c(1,2,2), c(2,1,1))
#
count <- 0
for (i in 1:(length(clusters))) {
# loop through all clusters
for (y in i:(length(clusters))) {
# check if in same cluster
if (clusters[i] == clusters[y]) {
# check if same class
if(classes[i] != classes[y]) {
# if same class, add lump error
count <- count + 1
}
}
}
}
return(count)
}
# test lump_errors function
0 == lump_error(c(1,2,2), c(2,1,1)) # true
2 == lump_error(c(1,2,2), c(1,1,1)) # true
0 == lump_error(c(1,2,2), c(4,5,6)) # true
split_error <- function(classes, clusters) {
# inputs: arg1: vector of classes
#         arg2: vector of clusters
# outputs: number of splitting errors
#
# usage: split_error(c(1,2,2), c(2,1,1))
#
count <- 0
for (i in 1:length(classes)) {
# loop through all clusters
for (y in i:length(classes)) {
# check if in same cluster
if (classes[i] == classes[y]) {
# check if same class
if (clusters[i] != clusters[y]) {
# if same class, add lump error
count <- count + 1
}
}
}
}
return(count)
}
# test split_error function
split_error(c(1,2,2), c(2,1,1))
split_error(c(1,2,2), c(2,1,2))
kc1
str(kc1)
## Section A ##
x1 = c(1, 1, 0, 5, 6, 4)
x2 = c(4, 3, 4, 1, 2, 0)
obs = c(1, 2, 3, 4, 5, 6)
data = data.frame(x1, x2)
plot(x1, x2, main="Scatterplot of Observations")
## Section B ##
set.seed(1)
sample_obs = sample(obs) # 2 6 3 4 1 5
cluster <- c(2, 1, 1, 2, 2, 1)
data <- data.frame(data, cluster)
# cluster labels:
(cluster)
c1 <- data.frame(
x1 <- c(1, 0, 4),
x2 <- c(3, 4, 0)
)
(centroid1_x1 <- mean(c(data[2,]$x1, data[3,]$x1, data[6,]$x1)))
(centroid1_x2 <- mean(c(data[2,]$x2, data[3,]$x2, data[6,]$x2)))
mean()c1$x1
mean(c1$x1)
mean(c1$x2)
? col.p
plot(x1, x2, col.p=c('red', 'blue'))
?plot
plot(x1[1:3], x2[1:3])
par(new=T)
plot(x1[4:6], x2[4:6])
plot(x1[1:3], x2[1:3])
par(new=FALSE)
plot(x1[4:6], x2[4:6])
x1
x2
x1 = c(1, 1, 0, 5, 6, 4)
x2 = c(4, 3, 4, 1, 2, 0)
plot(x1[1:3], x2[1:3])
par(new=FALSE)
plot(x1[4:6], x2[4:6])
plot(x1[1:3], x2[1:3])
par(new=TRUE)
plot(x1[4:6], x2[4:6])
plot(x1[1:3], x2[1:3])
lines(x1[4:6], x2[4:6])
plot(x1,x2)
plot(x1,x2)
lines(x1[1:3], x2[1:3], col="red")
lines(x1[4:6], x2[4:6], col="blue")
plot(x1,x2, main="Plot of Observations with Clustering")
lines(x1[1:3], x2[1:3], col="red")
lines(x1[4:6], x2[4:6], col="blue")
? lines
? lgened
? legend
plot(x1,x2, main="Plot of Observations with Clustering")
lines(x1[1:3], x2[1:3], col="red")
lines(x1[4:6], x2[4:6], col="blue")
legend(0, 0, c('1', '2'))
legend(0, 50, c('1', '2'))
legend(0, 20, c('1', '2'))
legend(0, 200, c('1', '2'))
plot(x1,x2, main="Plot of Observations with Clustering")
lines(x1[1:3], x2[1:3], col="red")
lines(x1[4:6], x2[4:6], col="blue")
legend(0, 200, c('1', '2'))
```
plot(x1,x2, main="Plot of Observations with Clustering")
lines(x1[1:3], x2[1:3], col="red")
lines(x1[4:6], x2[4:6], col="blue")
legend(0, 20, c('1', '2'))
? legend
legend(c(0,20), c('1', '2'))
plot(x1,x2, main="Plot of Observations with Clustering")
lines(x1[1:3], x2[1:3], col="red")
lines(x1[4:6], x2[4:6], col="blue")
legend(c(0,20), c('1', '2'))
plot(x1,x2, main="Plot of Observations with Clustering")
lines(x1[1:3], x2[1:3], col="red")
lines(x1[4:6], x2[4:6], col="blue")
legend(c(0,0), c('1', '2'))
legend(c(0,5), c('1', '2'))
legend(c(5,5), c('1', '2'))
legend(c(5,2), c('1', '2'))
legend(c(2,2), c('1', '2'))
plot(x1,x2, main="Plot of Observations with Clustering")
lines(x1[1:3], x2[1:3], col="red")
lines(x1[4:6], x2[4:6], col="blue")
legend(c(2,2), c('1', '2'))
legend(c(2,2), c('1', '2'), col='red', col='blue)
plot(x1,x2, main="Plot of Observations with Clustering")
lines(x1[1:3], x2[1:3], col="red")
lines(x1[4:6], x2[4:6], col="blue")
legend(c(2,2), c('1', '2'), col='red', col='blue)
```
plot(x1,x2, main="Plot of Observations with Clustering")
lines(x1[1:3], x2[1:3], col="red")
lines(x1[4:6], x2[4:6], col="blue")
legend(c(2,2), c('1', '2'), col='red', col='blue)
## Preliminaries ##
library(ElemStatLearn)
data(nci)
data <- nci
## Section A ##
set.seed(1)
kc1 <- kmeans(data, centers=14)
kc2 <- kmeans(data, centers=14)
kc3 <- kmeans(data, centers=14)
## Section B ##
# Part i
# Lump Error
lump_error <- function(classes, clusters) {
# inputs: arg1: vector of classes
#         arg2: vector of clusters
# outputs: number of lumping errors
#
# usage: lump_error(c(1,2,2), c(2,1,1))
#
count <- 0
for (i in 1:length(clusters)) {
# loop through all clusters
for (y in i:length(clusters)) {
# check if in same cluster
if (clusters[i] == clusters[y]) {
# check if same class
if (classes[i] != classes[y]) {
# if same class, add lump error
count <- count + 1
}
}
}
}
return(count)
}
# test lump_errors function
0 == lump_error(c(1,2,2), c(2,1,1)) # true
2 == lump_error(c(1,2,2), c(1,1,1)) # true
0 == lump_error(c(1,2,2), c(4,5,6)) # true
# Part ii
# Split Error
split_error <- function(classes, clusters) {
# inputs: arg1: vector of classes
#         arg2: vector of clusters
# outputs: number of splitting errors
#
# usage: split_error(c(1,2,2), c(2,1,1))
#
count <- 0
for (i in 1:length(classes)) {
# loop through all classess
for (y in i:length(classes)) {
# check if in same class
if (classes[i] == classes[y]) {
# check if same cluster
if (clusters[i] != clusters[y]) {
# if same cluster, add split error
count <- count + 1
}
}
}
}
return(count)
}
# test split_error function
1 == split_error(c(1,2,2), c(2,1,2)) # true
# Part iii
lump_error()
## Section C ##
split_error(c(1,2,2), c(2,1,1))
split_error(c(1,2,2), c(1,1,1))
kc1 <- kmeans(data, centers=14)
kc1
names(kc1)
c(1,2)
-c(1,2)
str(data)
names(data)
library(ElemStatLearn)
data(nci)
data <- nci
str(dta)
str(data)
names(data)
data
library(ElemStatLearn)
data(nci)
data <- nci
data
names(data)
head(data)
data$dimnames
head(data)
cars
cars$car
cars$cars
colnames(data)
data$CNS
nci
head(nci)
nci$CNR
plot(colnames(data))
colnames(data)
means <- apply(data, 2, mean)
stds <- apply(data, 2, sd)
data.us <- scale(data, center=means, scale=sds)
means <- apply(data, 2, mean)
sds <- apply(data, 2, sd)
data.use <- scale(data, center=means, scale=sds)
data.dist <- dist(data.use)
names(data.dist)
str(data.dist)
colnames(data.dist)
size(data.dist)
Size(data.dist)
length(data.dist)
data.use
names(data.use)
str(data.use)
colnames(data.use)
data.use$CNS
t(data)
data.trans <- t(data)
data.trans
means <- apply(data.trans, 2, mean)
means
sds <- apply(data.trans, 2, sd)
data.use <- scale(data.trans, center=means, scale=sds)
data.dist <- dist(data.use)
? rev
? diff
## Preliminaries ##
library(ElemStatLearn)
data(nci)
data <- nci
## Section A ##
set.seed(1)
kc1 <- kmeans(data, centers=14)
kc2 <- kmeans(data, centers=14)
kc3 <- kmeans(data, centers=14)
for (i in 1:30) {
print(i)
kc <- kmeans(data, centers=i)
}
summary(kc1)
for (i in 1:30) {
print(i)
kc <- kmeans(data, centers=i)
summary(kc)
}
for (i in 1:30) {
print(i)
kc <- kmeans(data, centers=i)
print(summary(kc))
}
for (i in 1:30) {
print('\n')
print(i)
kc <- kmeans(data, centers=i)
print(summary(kc))
}
for (i in 1:30) {
print("\n")
print(i)
kc <- kmeans(data, centers=i)
print(summary(kc))
}
for (i in 1:30) {
cat("\n")
print(i)
kc <- kmeans(data, centers=i)
print(summary(kc))
}
? kmeans
kmeans(t(data), centers=3)
summary(kmeans(t(data), centers=3))
plot(data, kc1)
plot(data, kc1$cluster)
plot(data, kc1$cluster+1)
for (i in 1:30) {
cat("\n")
print(i)
kc <- kmeans(data, centers=i)
print(summary(kc))
}
kc1$tot.withinss
## Section C ##
lines(i, kc$tot.withinss)
}
for (i in 1:30) {
cat("\n")
print(i)
kc <- kmeans(data, centers=i)
print(summary(kc))
lines(i, kc$tot.withinss)
}
plot(0,0)
for (i in 1:30) {
cat("\n")
print(i)
kc <- kmeans(data, centers=i)
print(summary(kc))
lines(i, kc$tot.withinss)
}
for (i in 1:30) {
cat("\n")
print(i)
kc <- kmeans(data, centers=i)
print(summary(kc))
plot(i, kc$tot.withinss)
}
? push
x <- 1:30
x
kc_list <- c()
kc_lits
kc_list
zed <- c()
zed <- c(1,zed)
zed
zed <- c(2,zed)
zed
zed <- c(zed,3)
zed <- c(zed,3)
zed
x <- 1:30
kc_list <- c()
for (i in 1:30) {
cat("\n")
print(i)
kc <- kmeans(data, centers=i)
print(summary(kc))
kc_list <- c(kc_list, kc$tot.withinss)
}
plot(x, kc_list)
x <- 1:30
kc_list <- c()
for (i in 1:30) {
# cat("\n")
# print(i)
kc <- kmeans(data, centers=i)
# print(summary(kc))
kc_list <- c(kc_list, kc$tot.withinss)
}
plot(x, kc_list, main="SSE against Number of Clusters")
sil <- 0
dis.mat <- dist(t(data))
for(k in 2:30) {
print(k)
cluster <- kmeans(t(data), k, nstart=25)$cluster
s <- silhouette(cluster, dis.mat)
ss <- summary(s)
sil[k] <- ss$avg.width
}
plot(1:30, sil, type="l", xlab="Number of Clusters")
for(k in 2:30) {
print(k)
cluster <- kmeans(t(data), k, nstart=25)$cluster
s <- silhouette(cluster, dis.mat)
ss <- summary(s)
sil[k] <- ss$avg.width
}
library(cluster)
sil <- 0
dis.mat <- dist(t(data))
for(k in 2:30) {
print(k)
cluster <- kmeans(t(data), k, nstart=25)$cluster
s <- silhouette(cluster, dis.mat)
ss <- summary(s)
sil[k] <- ss$avg.width
}
plot(1:30, sil, type="l", xlab="Number of Clusters")
hist(x, kc_list)
hist(kc_list)
kc1
summary(kc1)
x = c(1, 2, 3, 4)
x
x[]0
x[1]
x[1:]
x[1,]
x[1,end]
x[1,-1]
x[1,2]
x[1:]
x[1:x.length]
x[1:len(x)]
x[1:9]
names(x)
str(x)
x
help c
x.len
length(x)
x[1:length(x)]
importance(fit)
setwd('C:/Users/Graham/Desktop/FinalProject131/src')
source('prelims.R', local=TRUE)
dim(new.data)
dim(safety.data)
203-159
dim(safety.data)
dim(new.data)
str(safety.data)
44/203
? pie
pie(data$num.binary)
pie(data)
pie(safety.data$symboling)
data$num.binary
source('prelims.R', local=TRUE)
setwd('C:/Users/Graham/Desktop/FinalProject131/src')
source('prelims.R', local=TRUE)
data
data$num.binary
fit.price <- lm(data$num.binary ~., data=data)
